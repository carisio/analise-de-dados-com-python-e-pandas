{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capítulo 4 - Preparação de dados\n",
    "\n",
    "## Seção 2 - Tidy Data\n",
    "\n",
    "O objetivo é ter um conjunto de dados com os seguintes critérios:\n",
    "\n",
    "- Cada linha é uma observação\n",
    "- Cada coluna é uma variável\n",
    "- Cada tipo de unidade de observação forma uma tabela\n",
    "\n",
    "A ideia do último item colocar em uma tabela tudo que é necessário para responder uma pergunta. Do livro:\n",
    "\n",
    "\"Quando os dados estão organizados, é necessário combinar várias tabelas para responder a uma pergunta. Por exemplo, pode haver uma tabela separada que armazene informações de empresas e outra tabela contendo preços de ações. Se quisermos observar os preços de todas as ações no mercado de tecnologia, talvez antes tenhamos de encontrar todas as empresas de tecnologia na tabela de informações sobre empresas e então combinar esses dados com os dados de preços das ações a fim de obter as informações de que precisamos para responder à nossa pergunta. Os dados podem ter sido separados em tabelas distintas para reduzir a quantidade de informações redundantes (não precisamos armazenar informações sobre as empresas em cada entrada de preço das ações), mas essa organização implica que, como analista de dados, teremos de combinar os dados relevantes por conta própria para responder à nossa pergunta.\"\n",
    "\n",
    "\"Em outras ocasioes, um único conjunto de dados pode estar dividido em várias partes. Por exemplo, com dados de séries temporais, cada data pode estar em um arquivo separado. Em outro caso, um arquivo pode ter sido separado em partes para que os arquivos individuais fossem menores. Talvez você precise combinar dados de diversas origens para responder a uma pergunta (por exemplo, combinar latitudes e longitudes com CEPs). Nos dois casos, você terá de combinar dados em um único dataframe para análise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seção 3 - Concatenação\n",
    "\n",
    "A concatenação de dados no pandas é feita com a função _concat_. Um exemplo concatenando linhas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "0  a0  b0  c0  d0\n",
      "1  a1  b1  c1  d1\n",
      "2  a2  b2  c2  d2\n",
      "3  a3  b3  c3  d3 \n",
      "     A   B   C   D\n",
      "0  a4  b4  c4  d4\n",
      "1  a5  b5  c5  d5\n",
      "2  a6  b6  c6  d6\n",
      "3  a7  b7  c7  d7 \n",
      "      A    B    C    D\n",
      "0   a8   b8   c8   d8\n",
      "1   a9   b9   c9   d9\n",
      "2  a10  b10  c10  d10\n",
      "3  a11  b11  c11  d11 \n",
      "-----\n",
      "     A    B    C    D\n",
      "0   a0   b0   c0   d0\n",
      "1   a1   b1   c1   d1\n",
      "2   a2   b2   c2   d2\n",
      "3   a3   b3   c3   d3\n",
      "0   a4   b4   c4   d4\n",
      "1   a5   b5   c5   d5\n",
      "2   a6   b6   c6   d6\n",
      "3   a7   b7   c7   d7\n",
      "0   a8   b8   c8   d8\n",
      "1   a9   b9   c9   d9\n",
      "2  a10  b10  c10  d10\n",
      "3  a11  b11  c11  d11\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv('../data/concat_1.csv')\n",
    "df2 = pd.read_csv('../data/concat_2.csv')\n",
    "df3 = pd.read_csv('../data/concat_3.csv')\n",
    "\n",
    "print(df1, '\\n', df2, '\\n', df3, '\\n-----')\n",
    "\n",
    "row_concat = pd.concat([df1, df2, df3])\n",
    "print(row_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que _concat_ empilhou os dados, incluindo os rótulos dos índices. O resultado é que antes tínhamos 3 dataframes com rótulos 0, 1, 2 e 3. E agora temos um dataframe em que todos eles tem 3 rótulos 0, 3 rótulos 1 etc.\n",
    "\n",
    "Dessa forma, se quisermos buscar a primeira linha do dataframe, teremos que acessar com loc[0]. Se usarmos iloc[0] o pandas vai retornar um dataframe com as 3 linhas de rótulo 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    a0\n",
      "B    b0\n",
      "C    c0\n",
      "D    d0\n",
      "Name: 0, dtype: object\n",
      "------------\n",
      "    A   B   C   D\n",
      "0  a0  b0  c0  d0\n",
      "0  a4  b4  c4  d4\n",
      "0  a8  b8  c8  d8\n"
     ]
    }
   ],
   "source": [
    "print(row_concat.iloc[0])\n",
    "\n",
    "print('------------')\n",
    "\n",
    "print(row_concat.loc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É necessário ter as colunas alinhadas com o que se deseja concatenar. Se concatenar uma série sem especificar as colunas (ou seja, a série está desalinhada com o dataframe que já existe), o resultado será que uma nova coluna será criada pra nova série:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C    D    0\n",
      "0   a0   b0   c0   d0  NaN\n",
      "1   a1   b1   c1   d1  NaN\n",
      "2   a2   b2   c2   d2  NaN\n",
      "3   a3   b3   c3   d3  NaN\n",
      "0  NaN  NaN  NaN  NaN   n1\n",
      "1  NaN  NaN  NaN  NaN   n2\n",
      "2  NaN  NaN  NaN  NaN   n3\n",
      "3  NaN  NaN  NaN  NaN   n4\n"
     ]
    }
   ],
   "source": [
    "new_row_series = pd.Series(['n1', 'n2', 'n3', 'n4'])\n",
    "\n",
    "print(pd.concat([df1, new_row_series]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O jeito certo de concatenar isso é criando um dataframe. Um serie nomeada não funciona. da série ou criando um novo dataframe com as mesmas colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Essa series com os indices nomeados como coluna não funciona:\n",
      "     A    B    C    D    0\n",
      "0   a0   b0   c0   d0  NaN\n",
      "1   a1   b1   c1   d1  NaN\n",
      "2   a2   b2   c2   d2  NaN\n",
      "3   a3   b3   c3   d3  NaN\n",
      "A  NaN  NaN  NaN  NaN   n1\n",
      "B  NaN  NaN  NaN  NaN   n2\n",
      "C  NaN  NaN  NaN  NaN   n3\n",
      "D  NaN  NaN  NaN  NaN   n4\n",
      "----------\n",
      "Já esse dataframe com as mesmas colunas funciona corretamente:\n",
      "    A   B   C   D\n",
      "0  a0  b0  c0  d0\n",
      "1  a1  b1  c1  d1\n",
      "2  a2  b2  c2  d2\n",
      "3  a3  b3  c3  d3\n",
      "0  n1  n2  n3  n4\n"
     ]
    }
   ],
   "source": [
    "new_row_series = pd.Series({'A': 'n1', 'B': 'n2', 'C': 'n3', 'D': 'n4'})\n",
    "print('Essa series com os indices nomeados como coluna não funciona:')\n",
    "print(pd.concat([df1, new_row_series]))\n",
    "print('----------')\n",
    "new_row_df = pd.DataFrame([['n1', 'n2', 'n3', 'n4']], columns=['A', 'B', 'C', 'D'])\n",
    "print('Já esse dataframe com as mesmas colunas funciona corretamente:')\n",
    "print(pd.concat([df1, new_row_df]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A questão dos rótulos pode ser resolvida usando o parâmetro ignore_index=True:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      A    B    C    D\n",
      "0    a0   b0   c0   d0\n",
      "1    a1   b1   c1   d1\n",
      "2    a2   b2   c2   d2\n",
      "3    a3   b3   c3   d3\n",
      "4    a4   b4   c4   d4\n",
      "5    a5   b5   c5   d5\n",
      "6    a6   b6   c6   d6\n",
      "7    a7   b7   c7   d7\n",
      "8    a8   b8   c8   d8\n",
      "9    a9   b9   c9   d9\n",
      "10  a10  b10  c10  d10\n",
      "11  a11  b11  c11  d11\n"
     ]
    }
   ],
   "source": [
    "print(pd.concat([df1, df2, df3], ignore_index=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A concatenação de colunas com concat é igual a de linhas, exceto que nesse caso é necessário passar o parâmetro axis=1. Os nomes de colunas podem ficar duplicados se os dataframes tiverem o mesmo nome de colunas. É necessário renomear usando o atributo columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D   A   B   C   D    A    B    C    D\n",
      "0  a0  b0  c0  d0  a4  b4  c4  d4   a8   b8   c8   d8\n",
      "1  a1  b1  c1  d1  a5  b5  c5  d5   a9   b9   c9   d9\n",
      "2  a2  b2  c2  d2  a6  b6  c6  d6  a10  b10  c10  d10\n",
      "3  a3  b3  c3  d3  a7  b7  c7  d7  a11  b11  c11  d11\n",
      "Depois de alterado o nome das colunas:\n",
      "    A   B   C   D   E   F   G   H    I    J    K    L\n",
      "0  a0  b0  c0  d0  a4  b4  c4  d4   a8   b8   c8   d8\n",
      "1  a1  b1  c1  d1  a5  b5  c5  d5   a9   b9   c9   d9\n",
      "2  a2  b2  c2  d2  a6  b6  c6  d6  a10  b10  c10  d10\n",
      "3  a3  b3  c3  d3  a7  b7  c7  d7  a11  b11  c11  d11\n"
     ]
    }
   ],
   "source": [
    "col_concat = pd.concat([df1, df2, df3], axis=1)\n",
    "print(col_concat)\n",
    "\n",
    "print('Depois de alterado o nome das colunas:')\n",
    "col_concat.columns = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L']\n",
    "print(col_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pra adicionar uma única coluna, basta atribuir direto ao nome da nova coluna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D   E   F   G   H    I    J    K    L  nova\n",
      "0  a0  b0  c0  d0  a4  b4  c4  d4   a8   b8   c8   d8     1\n",
      "1  a1  b1  c1  d1  a5  b5  c5  d5   a9   b9   c9   d9     2\n",
      "2  a2  b2  c2  d2  a6  b6  c6  d6  a10  b10  c10  d10     3\n",
      "3  a3  b3  c3  d3  a7  b7  c7  d7  a11  b11  c11  d11     4\n"
     ]
    }
   ],
   "source": [
    "col_concat['nova'] = [1, 2, 3, 4]\n",
    "print(col_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na concatenação de dataframes com diferentes rótulos de colunas/linhas, o pandas vai tentar casar os dataframes de acordo com as colunas/linhas e colocar NaN no resto.\n",
    "\n",
    "Vamos ver primeiro como funciona concatenando linhas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "0  a0  b0  c0  d0\n",
      "1  a1  b1  c1  d1\n",
      "2  a2  b2  c2  d2\n",
      "3  a3  b3  c3  d3 \n",
      "     E   F   G   H\n",
      "0  a4  b4  c4  d4\n",
      "1  a5  b5  c5  d5\n",
      "2  a6  b6  c6  d6\n",
      "3  a7  b7  c7  d7 \n",
      "      A    C    F    H\n",
      "0   a8   b8   c8   d8\n",
      "1   a9   b9   c9   d9\n",
      "2  a10  b10  c10  d10\n",
      "3  a11  b11  c11  d11\n"
     ]
    }
   ],
   "source": [
    "df1.columns = ['A', 'B', 'C', 'D']\n",
    "df2.columns = ['E', 'F', 'G', 'H']\n",
    "df3.columns = ['A', 'C', 'F', 'H']\n",
    "\n",
    "print(df1, '\\n', df2, '\\n', df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df1 tem as colunas A e C em comum com df3.\n",
    "df2 tem as colunas F e H em comum com df3.\n",
    "\n",
    "Se tentarmos concatenar esses 3 dataframes, no final teremos as colunas A, B, C, D, E, F, G, H.\n",
    "\n",
    "- Os dados de df1 ocuparão as linhas 0:4 e as colunas A, B, C, D.\n",
    "- Os dados de df2 ocuparão as linhas 4:8 e as colunas E, F, G, H.\n",
    "- Os dados de df3 ocuparão as linhas 8:12 e estarão nas colunas A, C, F, H.\n",
    "\n",
    "Todos os outros dados serão completados com NaN, que é a forma como o pandas representa os valores faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C    D    E    F    G    H\n",
      "0   a0   b0   c0   d0  NaN  NaN  NaN  NaN\n",
      "1   a1   b1   c1   d1  NaN  NaN  NaN  NaN\n",
      "2   a2   b2   c2   d2  NaN  NaN  NaN  NaN\n",
      "3   a3   b3   c3   d3  NaN  NaN  NaN  NaN\n",
      "0  NaN  NaN  NaN  NaN   a4   b4   c4   d4\n",
      "1  NaN  NaN  NaN  NaN   a5   b5   c5   d5\n",
      "2  NaN  NaN  NaN  NaN   a6   b6   c6   d6\n",
      "3  NaN  NaN  NaN  NaN   a7   b7   c7   d7\n",
      "0   a8  NaN   b8  NaN  NaN   c8  NaN   d8\n",
      "1   a9  NaN   b9  NaN  NaN   c9  NaN   d9\n",
      "2  a10  NaN  b10  NaN  NaN  c10  NaN  d10\n",
      "3  a11  NaN  b11  NaN  NaN  c11  NaN  d11\n"
     ]
    }
   ],
   "source": [
    "print(pd.concat([df1, df2, df3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse comportamento é o padrão de pandas de fazer a concatenação como uma união entre os conjuntos. É possível também fazer ocmo uma interseção. Para isso, podemos usar o parâmetro join='inner' (o default é join='outer').\n",
    "\n",
    "Como não há nenhuma coluna em comum com os três dataframes, o join de intersecção entre eles é um dataframe vazio. Mas o join entre os dataframes (df1 e df3) e (df2 e df3) produzem resultados com as colunas em comum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inner join entre df1, df2 e df3:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3]\n",
      "----------------------------\n",
      "Inner join entre df1 e df3:\n",
      "     A    C\n",
      "0   a0   c0\n",
      "1   a1   c1\n",
      "2   a2   c2\n",
      "3   a3   c3\n",
      "0   a8   b8\n",
      "1   a9   b9\n",
      "2  a10  b10\n",
      "3  a11  b11\n",
      "----------------------------\n",
      "Inner join entre df2 e df3:\n",
      "     F    H\n",
      "0   b4   d4\n",
      "1   b5   d5\n",
      "2   b6   d6\n",
      "3   b7   d7\n",
      "0   c8   d8\n",
      "1   c9   d9\n",
      "2  c10  d10\n",
      "3  c11  d11\n"
     ]
    }
   ],
   "source": [
    "print('Inner join entre df1, df2 e df3:')\n",
    "print(pd.concat([df1, df2, df3], join='inner'))\n",
    "print('----------------------------')\n",
    "print('Inner join entre df1 e df3:')\n",
    "print(pd.concat([df1, df3], join='inner'))\n",
    "print('----------------------------')\n",
    "print('Inner join entre df2 e df3:')\n",
    "print(pd.concat([df2, df3], join='inner'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A concatenação de colunas casando as linhas possui o mesmo funcionamento. Para ilustrar, vamos alterar os índices de forma que df1 e df2 tenham índices totalmente diferentes e df3 possua índices em comum com df1 e df2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "0  a0  b0  c0  d0\n",
      "1  a1  b1  c1  d1\n",
      "2  a2  b2  c2  d2\n",
      "3  a3  b3  c3  d3 \n",
      "     E   F   G   H\n",
      "4  a4  b4  c4  d4\n",
      "5  a5  b5  c5  d5\n",
      "6  a6  b6  c6  d6\n",
      "7  a7  b7  c7  d7 \n",
      "      A    C    F    H\n",
      "0   a8   b8   c8   d8\n",
      "2   a9   b9   c9   d9\n",
      "5  a10  b10  c10  d10\n",
      "7  a11  b11  c11  d11\n"
     ]
    }
   ],
   "source": [
    "df1.index = [0, 1, 2, 3]\n",
    "df2.index = [4, 5, 6, 7]\n",
    "df3.index = [0, 2, 5, 7]\n",
    "\n",
    "print(df1, '\\n', df2, '\\n', df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se formos concatenar os 3 df2 em colunas (e casando as linhas), teremos um dataframe com 8 linhas e com os índices 0...7. Os índices terão dados provenientes dos seguintes dataframes:\n",
    "\n",
    "- 0: df1 (A, B, C, D) e df3 (A, C, F, H)\n",
    "- 1: df1 (A, B, C, D)\n",
    "- 2: df1 (A, B, C, D) e df3 (A, C, F, H)\n",
    "- 3: df1 (A, B, C, D)\n",
    "- 4: df2 (E, F, G, H)\n",
    "- 5: df2 (E, F, G, H) e df3 (A, C, F, H)\n",
    "- 6: df2 (E, F, G, H)\n",
    "- 7: df2 (E, F, G, H) e df3 (A, C, F, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C    D    E    F    G    H    A    C    F    H\n",
      "0   a0   b0   c0   d0  NaN  NaN  NaN  NaN   a8   b8   c8   d8\n",
      "1   a1   b1   c1   d1  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
      "2   a2   b2   c2   d2  NaN  NaN  NaN  NaN   a9   b9   c9   d9\n",
      "3   a3   b3   c3   d3  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
      "4  NaN  NaN  NaN  NaN   a4   b4   c4   d4  NaN  NaN  NaN  NaN\n",
      "5  NaN  NaN  NaN  NaN   a5   b5   c5   d5  a10  b10  c10  d10\n",
      "6  NaN  NaN  NaN  NaN   a6   b6   c6   d6  NaN  NaN  NaN  NaN\n",
      "7  NaN  NaN  NaN  NaN   a7   b7   c7   d7  a11  b11  c11  d11\n"
     ]
    }
   ],
   "source": [
    "print(pd.concat([df1, df2, df3], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seção 4 - Combinando vários conjuntos de dados\n",
    "\n",
    "De forma mais geral, podemos combinar diversos conjuntos de dados usando função merge e fazer algo semelhante com os join do SQL (inner join e left/right/full outer join).\n",
    "\n",
    "Para testar, vamos abrir algumas bases de dados e visualizar o seu conteúdo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ident   personal    family\n",
      "0      dyer    William      Dyer\n",
      "1        pb      Frank   Pabodie\n",
      "2      lake   Anderson      Lake\n",
      "3       roe  Valentina   Roerich\n",
      "4  danforth      Frank  Danforth\n",
      "----------------------------------------------\n",
      "    name    lat    long\n",
      "0   DR-1 -49.85 -128.57\n",
      "1   DR-3 -47.15 -126.72\n",
      "2  MSK-4 -48.87 -123.40\n",
      "----------------------------------------------\n",
      "    taken person quant  reading\n",
      "0     619   dyer   rad     9.82\n",
      "1     619   dyer   sal     0.13\n",
      "2     622   dyer   rad     7.80\n",
      "3     622   dyer   sal     0.09\n",
      "4     734     pb   rad     8.41\n",
      "5     734   lake   sal     0.05\n",
      "6     734     pb  temp   -21.50\n",
      "7     735     pb   rad     7.22\n",
      "8     735    NaN   sal     0.06\n",
      "9     735    NaN  temp   -26.00\n",
      "10    751     pb   rad     4.35\n",
      "11    751     pb  temp   -18.50\n",
      "12    751   lake   sal     0.10\n",
      "13    752   lake   rad     2.19\n",
      "14    752   lake   sal     0.09\n",
      "15    752   lake  temp   -16.00\n",
      "16    752    roe   sal    41.60\n",
      "17    837   lake   rad     1.46\n",
      "18    837   lake   sal     0.21\n",
      "19    837    roe   sal    22.50\n",
      "20    844    roe   rad    11.25\n",
      "----------------------------------------------\n",
      "   ident   site       dated\n",
      "0    619   DR-1  1927-02-08\n",
      "1    622   DR-1  1927-02-10\n",
      "2    734   DR-3  1939-01-07\n",
      "3    735   DR-3  1930-01-12\n",
      "4    751   DR-3  1930-02-26\n",
      "5    752   DR-3         NaN\n",
      "6    837  MSK-4  1932-01-14\n",
      "7    844   DR-1  1932-03-22\n"
     ]
    }
   ],
   "source": [
    "person = pd.read_csv('../data/survey_person.csv')\n",
    "site = pd.read_csv('../data/survey_site.csv')\n",
    "survey = pd.read_csv('../data/survey_survey.csv')\n",
    "visited = pd.read_csv('../data/survey_visited.csv')\n",
    "\n",
    "print(person)\n",
    "print('----------------------------------------------')\n",
    "print(site)\n",
    "print('----------------------------------------------')\n",
    "print(survey)\n",
    "print('----------------------------------------------')\n",
    "print(visited)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ilustrar, vamos fazer um merge de n:1 (ou 1:n). Para isso, fazemos o seguinte:\n",
    "\n",
    "- chamamos o método merge a um dataframe passando outro dataframe como parâmetro. \n",
    "- o dataframe em que o método é chamado é o left. O outro, right.\n",
    "- informamos a coluna em que o merge é aplicado através do parâmetro 'on'. Caso o nome das colunas seja diferentes nos dois dataframes, podemos usar left_on e right_on\n",
    "- informamos a forma do merge no parâmetro how (inner, outer, left, right). O valor default é inner.\n",
    "\n",
    "Podemos modificar o passo 2 para fazer o merge baseando em várias colunas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>ident</th>\n",
       "      <th>site</th>\n",
       "      <th>dated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DR-1</td>\n",
       "      <td>-49.85</td>\n",
       "      <td>-128.57</td>\n",
       "      <td>619</td>\n",
       "      <td>DR-1</td>\n",
       "      <td>1927-02-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DR-1</td>\n",
       "      <td>-49.85</td>\n",
       "      <td>-128.57</td>\n",
       "      <td>622</td>\n",
       "      <td>DR-1</td>\n",
       "      <td>1927-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DR-1</td>\n",
       "      <td>-49.85</td>\n",
       "      <td>-128.57</td>\n",
       "      <td>844</td>\n",
       "      <td>DR-1</td>\n",
       "      <td>1932-03-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR-3</td>\n",
       "      <td>-47.15</td>\n",
       "      <td>-126.72</td>\n",
       "      <td>734</td>\n",
       "      <td>DR-3</td>\n",
       "      <td>1939-01-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DR-3</td>\n",
       "      <td>-47.15</td>\n",
       "      <td>-126.72</td>\n",
       "      <td>735</td>\n",
       "      <td>DR-3</td>\n",
       "      <td>1930-01-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DR-3</td>\n",
       "      <td>-47.15</td>\n",
       "      <td>-126.72</td>\n",
       "      <td>751</td>\n",
       "      <td>DR-3</td>\n",
       "      <td>1930-02-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DR-3</td>\n",
       "      <td>-47.15</td>\n",
       "      <td>-126.72</td>\n",
       "      <td>752</td>\n",
       "      <td>DR-3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MSK-4</td>\n",
       "      <td>-48.87</td>\n",
       "      <td>-123.40</td>\n",
       "      <td>837</td>\n",
       "      <td>MSK-4</td>\n",
       "      <td>1932-01-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name    lat    long  ident   site       dated\n",
       "0   DR-1 -49.85 -128.57    619   DR-1  1927-02-08\n",
       "1   DR-1 -49.85 -128.57    622   DR-1  1927-02-10\n",
       "2   DR-1 -49.85 -128.57    844   DR-1  1932-03-22\n",
       "3   DR-3 -47.15 -126.72    734   DR-3  1939-01-07\n",
       "4   DR-3 -47.15 -126.72    735   DR-3  1930-01-12\n",
       "5   DR-3 -47.15 -126.72    751   DR-3  1930-02-26\n",
       "6   DR-3 -47.15 -126.72    752   DR-3         NaN\n",
       "7  MSK-4 -48.87 -123.40    837  MSK-4  1932-01-14"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "site.merge(visited, left_on='name', right_on='site')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
