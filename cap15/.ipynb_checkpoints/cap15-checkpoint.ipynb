{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3f9bf1d",
   "metadata": {},
   "source": [
    "# Capítulo 15 - Regularização\n",
    "\n",
    "## Seção 15.2 - Por que regularizar?\n",
    "\n",
    "Regularização é uma técnica usada para reduzir o overfitting.Vamos ilustrar isso com um caso básico de regressão linear:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a88298c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Acres', 'FamilyIncome', 'FamilyType', 'NumBedrooms', 'NumChildren',\n",
      "       'NumPeople', 'NumRooms', 'NumUnits', 'NumVehicles', 'NumWorkers',\n",
      "       'OwnRent', 'YearBuilt', 'HouseCosts', 'ElectricBill', 'FoodStamp',\n",
      "       'HeatingFuel', 'Insurance', 'Language'],\n",
      "      dtype='object')\n",
      "                       variable       coef_lr\n",
      "0                     Intercept  3.522660e-11\n",
      "1   NumUnits[T.Single attached]  3.135646e+04\n",
      "2   NumUnits[T.Single detached]  2.418368e+04\n",
      "3           OwnRent[T.Outright]  2.839186e+04\n",
      "4             OwnRent[T.Rented]  7.229586e+03\n",
      "5        YearBuilt[T.1940-1949]  1.292169e+04\n",
      "6        YearBuilt[T.1950-1959]  2.057793e+04\n",
      "7        YearBuilt[T.1960-1969]  1.764835e+04\n",
      "8        YearBuilt[T.1970-1979]  1.756881e+04\n",
      "9        YearBuilt[T.1980-1989]  2.552566e+04\n",
      "10       YearBuilt[T.1990-1999]  2.983944e+04\n",
      "11       YearBuilt[T.2000-2004]  3.012502e+04\n",
      "12            YearBuilt[T.2005]  4.318648e+04\n",
      "13            YearBuilt[T.2006]  3.242038e+04\n",
      "14            YearBuilt[T.2007]  3.562061e+04\n",
      "15            YearBuilt[T.2008]  3.712470e+04\n",
      "16            YearBuilt[T.2009]  3.035133e+04\n",
      "17            YearBuilt[T.2010]  7.364529e+04\n",
      "18     YearBuilt[T.Before 1939]  1.218711e+04\n",
      "19             FoodStamp[T.Yes] -2.745712e+04\n",
      "20   HeatingFuel[T.Electricity]  1.946552e+04\n",
      "21           HeatingFuel[T.Gas]  2.588482e+04\n",
      "22          HeatingFuel[T.None]  2.532452e+04\n",
      "23           HeatingFuel[T.Oil]  2.535803e+04\n",
      "24         HeatingFuel[T.Other]  1.734533e+04\n",
      "25         HeatingFuel[T.Solar]  8.424991e+03\n",
      "26          HeatingFuel[T.Wood]  8.898002e+02\n",
      "27          Language[T.English] -1.873624e+04\n",
      "28            Language[T.Other] -4.463333e+03\n",
      "29   Language[T.Other European] -1.409466e+04\n",
      "30          Language[T.Spanish] -2.603347e+04\n",
      "31                  NumBedrooms  3.443931e+03\n",
      "32                  NumChildren  8.215723e+03\n",
      "33                    NumPeople -8.203826e+03\n",
      "34                     NumRooms  5.735494e+03\n",
      "35                  NumVehicles  7.484535e+03\n",
      "36                   NumWorkers  2.283630e+04\n",
      "37                 ElectricBill  9.332524e+01\n",
      "38                    Insurance  3.099441e+01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caris\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from patsy import dmatrices \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "acs = pd.read_csv('../data/acs_ny.csv')\n",
    "print(acs.columns)\n",
    "\n",
    "# Cria matrizes de resposta e preditores a partir de uma fórmula\n",
    "response, predictors = dmatrices('FamilyIncome ~ NumBedrooms + NumChildren + NumPeople + NumRooms + '\\\n",
    "                                 'NumUnits + NumVehicles + NumWorkers + OwnRent + YearBuilt + ElectricBill + '\\\n",
    "                                 'FoodStamp + HeatingFuel + Insurance + Language', data=acs)\n",
    "\n",
    "# Agora divide os dados em um conjunto de teste e um conjunto de treinamento\n",
    "x_train, x_test, y_train, y_test = train_test_split(predictors, response, random_state=0)\n",
    "\n",
    "# E agora vamos fazer uma regressão linear com os dados de treinamento\n",
    "lr = LinearRegression(normalize=True).fit(x_train, y_train)\n",
    "\n",
    "model_coefs = pd.DataFrame(list(zip(predictors.design_info.column_names, lr.coef_[0])), columns=['variable', 'coef_lr'])\n",
    "print(model_coefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cd2a93",
   "metadata": {},
   "source": [
    "E agora vamo checar qual é o score (R^2) do modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "599fad2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2726140465638569\n",
      "0.26976979568488124\n"
     ]
    }
   ],
   "source": [
    "print(lr.score(x_train, y_train))\n",
    "\n",
    "print(lr.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3275f208",
   "metadata": {},
   "source": [
    "O score é muito baixo, o que mostra um desempenho ruim do modelo.\n",
    "\n",
    "Num cenário útil em que a regularização é necessária, a gente veria um valor de R2 alto no conjunto de treinamento e baixo no conjunto de teste, indicando o overfitting do modelo.\n",
    "\n",
    "E aí com regularização a gente diminuiria o peso dos coeficientes de cada um deles. Há alguns tipos de regularização e nas seções seguintes o livro não explica o funcionamento delas, apenas usa.\n",
    "\n",
    "Obs.: é incrível que o livro tenha usado esse exemplo tosco pra embasar o assunto de regularização.\n",
    "\n",
    "## Seção 15.3 - Regressão LASSO (Least Absolute Shrinkage and Selection Operator)\n",
    "\n",
    "Essa regressão também é conhecida como regressão com regularização L1 permite até mesmo zerar alguns coeficientes (descartando variáveis):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baa9b9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       variable       coef_lr\n",
      "0                     Intercept      0.000000\n",
      "1   NumUnits[T.Single attached]  28192.431471\n",
      "2   NumUnits[T.Single detached]  21101.168897\n",
      "3           OwnRent[T.Outright]  27074.779758\n",
      "4             OwnRent[T.Rented]   6274.559912\n",
      "5        YearBuilt[T.1940-1949]  -7081.568645\n",
      "6        YearBuilt[T.1950-1959]      0.000000\n",
      "7        YearBuilt[T.1960-1969]  -2429.382254\n",
      "8        YearBuilt[T.1970-1979]  -2798.031405\n",
      "9        YearBuilt[T.1980-1989]   4410.551326\n",
      "10       YearBuilt[T.1990-1999]   8550.687504\n",
      "11       YearBuilt[T.2000-2004]   8696.421930\n",
      "12            YearBuilt[T.2005]  20967.365359\n",
      "13            YearBuilt[T.2006]  10594.529271\n",
      "14            YearBuilt[T.2007]  13591.992592\n",
      "15            YearBuilt[T.2008]  14617.015659\n",
      "16            YearBuilt[T.2009]   7408.678779\n",
      "17            YearBuilt[T.2010]  50201.873426\n",
      "18     YearBuilt[T.Before 1939]  -8240.050914\n",
      "19             FoodStamp[T.Yes] -27585.672088\n",
      "20   HeatingFuel[T.Electricity]   1108.339163\n",
      "21           HeatingFuel[T.Gas]   7840.605594\n",
      "22          HeatingFuel[T.None]   1839.122626\n",
      "23           HeatingFuel[T.Oil]   7117.730794\n",
      "24         HeatingFuel[T.Other]     -0.000000\n",
      "25         HeatingFuel[T.Solar]   -986.883075\n",
      "26          HeatingFuel[T.Wood] -16526.230787\n",
      "27          Language[T.English] -14814.270759\n",
      "28            Language[T.Other]     -0.000000\n",
      "29   Language[T.Other European]  -9795.537966\n",
      "30          Language[T.Spanish] -21812.825194\n",
      "31                  NumBedrooms   3315.392605\n",
      "32                  NumChildren   7655.401889\n",
      "33                    NumPeople  -7624.772460\n",
      "34                     NumRooms   5722.157633\n",
      "35                  NumVehicles   7195.818883\n",
      "36                   NumWorkers  22504.998102\n",
      "37                 ElectricBill     92.562960\n",
      "38                    Insurance     30.946224\n",
      "0.2722281509897315\n",
      "0.2704460855794786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caris\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# O livro faz isso com os dados de teste, mas o certo é sempre usar os dados de treinamento\n",
    "lasso = Lasso(normalize=True, random_state=0).fit(x_train, y_train)\n",
    "\n",
    "coefs_lasso = pd.DataFrame(list(zip(predictors.design_info.column_names, lasso.coef_)), columns=['variable', 'coef_lr'])\n",
    "print(coefs_lasso)\n",
    "\n",
    "print(lasso.score(x_train, y_train))\n",
    "print(lasso.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8561b5f8",
   "metadata": {},
   "source": [
    "## Seção 15.4 - Regressão de ridge\n",
    "\n",
    "Também é conhecida como regressão com regularização L2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a84f6dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       variable       coef_lr\n",
      "0                     Intercept      0.000000\n",
      "1   NumUnits[T.Single attached]   4571.129321\n",
      "2   NumUnits[T.Single detached]   4514.956813\n",
      "3           OwnRent[T.Outright]  10674.890982\n",
      "4             OwnRent[T.Rented] -10180.631863\n",
      "5        YearBuilt[T.1940-1949]  -3672.096659\n",
      "6        YearBuilt[T.1950-1959]   1221.616020\n",
      "7        YearBuilt[T.1960-1969]    -15.801437\n",
      "8        YearBuilt[T.1970-1979]  -1868.746915\n",
      "9        YearBuilt[T.1980-1989]   2664.343363\n",
      "10       YearBuilt[T.1990-1999]   4079.639281\n",
      "11       YearBuilt[T.2000-2004]   5615.285677\n",
      "12            YearBuilt[T.2005]  12607.557029\n",
      "13            YearBuilt[T.2006]   5783.401233\n",
      "14            YearBuilt[T.2007]   8019.076178\n",
      "15            YearBuilt[T.2008]   7964.342869\n",
      "16            YearBuilt[T.2009]   3892.605415\n",
      "17            YearBuilt[T.2010]  28469.966885\n",
      "18     YearBuilt[T.Before 1939]  -4271.925584\n",
      "19             FoodStamp[T.Yes] -21854.708263\n",
      "20   HeatingFuel[T.Electricity]  -2043.214963\n",
      "21           HeatingFuel[T.Gas]   2043.550077\n",
      "22          HeatingFuel[T.None]   1376.185561\n",
      "23           HeatingFuel[T.Oil]   2377.402169\n",
      "24         HeatingFuel[T.Other]  -5135.068670\n",
      "25         HeatingFuel[T.Solar]    589.799008\n",
      "26          HeatingFuel[T.Wood] -13652.201413\n",
      "27          Language[T.English]  -3003.249668\n",
      "28            Language[T.Other]   9067.969977\n",
      "29   Language[T.Other European]   3059.003880\n",
      "30          Language[T.Spanish]  -6155.075714\n",
      "31                  NumBedrooms   4690.469564\n",
      "32                  NumChildren   1102.877585\n",
      "33                    NumPeople   -203.132130\n",
      "34                     NumRooms   3489.196546\n",
      "35                  NumVehicles   5245.929228\n",
      "36                   NumWorkers  10344.202715\n",
      "37                 ElectricBill     68.784409\n",
      "38                    Insurance     15.914804\n",
      "0.22808926982778643\n",
      "0.2325127754670412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caris\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = Ridge(normalize=True, random_state=0).fit(x_train, y_train)\n",
    "\n",
    "coefs_ridge = pd.DataFrame(list(zip(predictors.design_info.column_names, ridge.coef_[0])), columns=['variable', 'coef_lr'])\n",
    "print(coefs_ridge)\n",
    "\n",
    "print(ridge.score(x_train, y_train))\n",
    "print(ridge.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20199981",
   "metadata": {},
   "source": [
    "## Seção 15.5 - Rede elástica\n",
    "\n",
    "Combina as duas técnicas de regularização anteriores (LASSO e Ridge):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6f82767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       variable       coef_lr       coef_en\n",
      "0                     Intercept  3.522660e-11      0.000000\n",
      "1   NumUnits[T.Single attached]  3.135646e+04   1342.291706\n",
      "2   NumUnits[T.Single detached]  2.418368e+04    168.728479\n",
      "3           OwnRent[T.Outright]  2.839186e+04    445.533238\n",
      "4             OwnRent[T.Rented]  7.229586e+03   -600.673747\n",
      "5        YearBuilt[T.1940-1949]  1.292169e+04   -794.239494\n",
      "6        YearBuilt[T.1950-1959]  2.057793e+04    513.289101\n",
      "7        YearBuilt[T.1960-1969]  1.764835e+04   -275.576200\n",
      "8        YearBuilt[T.1970-1979]  1.756881e+04   -574.365605\n",
      "9        YearBuilt[T.1980-1989]  2.552566e+04    708.813588\n",
      "10       YearBuilt[T.1990-1999]  2.983944e+04   1357.944466\n",
      "11       YearBuilt[T.2000-2004]  3.012502e+04    798.576141\n",
      "12            YearBuilt[T.2005]  4.318648e+04    445.271666\n",
      "13            YearBuilt[T.2006]  3.242038e+04    202.040682\n",
      "14            YearBuilt[T.2007]  3.562061e+04    222.170314\n",
      "15            YearBuilt[T.2008]  3.712470e+04    153.161478\n",
      "16            YearBuilt[T.2009]  3.035133e+04     88.228204\n",
      "17            YearBuilt[T.2010]  7.364529e+04    233.189152\n",
      "18     YearBuilt[T.Before 1939]  1.218711e+04  -3053.705550\n",
      "19             FoodStamp[T.Yes] -2.745712e+04  -4394.455708\n",
      "20   HeatingFuel[T.Electricity]  1.946552e+04   -129.968032\n",
      "21           HeatingFuel[T.Gas]  2.588482e+04   1924.299033\n",
      "22          HeatingFuel[T.None]  2.532452e+04      0.000000\n",
      "23           HeatingFuel[T.Oil]  2.535803e+04    453.942244\n",
      "24         HeatingFuel[T.Other]  1.734533e+04    -67.445065\n",
      "25         HeatingFuel[T.Solar]  8.424991e+03      0.994142\n",
      "26          HeatingFuel[T.Wood]  8.898002e+02  -1894.123724\n",
      "27          Language[T.English] -1.873624e+04   -955.455328\n",
      "28            Language[T.Other] -4.463333e+03    374.835549\n",
      "29   Language[T.Other European] -1.409466e+04    626.547311\n",
      "30          Language[T.Spanish] -2.603347e+04  -1367.763935\n",
      "31                  NumBedrooms  3.443931e+03   2073.910045\n",
      "32                  NumChildren  8.215723e+03   2498.719581\n",
      "33                    NumPeople -8.203826e+03  -2562.412933\n",
      "34                     NumRooms  5.735494e+03   5685.101939\n",
      "35                  NumVehicles  7.484535e+03   6059.776166\n",
      "36                   NumWorkers  2.283630e+04  12247.547800\n",
      "37                 ElectricBill  9.332524e+01     97.566664\n",
      "38                    Insurance  3.099441e+01     32.484207\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "en = ElasticNet(random_state=42).fit(x_train, y_train)\n",
    "\n",
    "\n",
    "coefs_en = pd.DataFrame(list(zip(predictors.design_info.column_names, en.coef_)), columns=['variable', 'coef_en'])\n",
    "\n",
    "model_coefs=pd.merge(model_coefs, coefs_en, on='variable')\n",
    "print(model_coefs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
